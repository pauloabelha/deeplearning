{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from string import ascii_lowercase\n",
    "import sys\n",
    "import pickle\n",
    "from xml.etree.ElementTree import tostring\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "# base URL\n",
    "page_root_url = 'http://www.jokebuddha.com/'\n",
    "# file name for the topics\n",
    "topics_filename = 'topics.p'\n",
    "# filename for the jokes\n",
    "jokes_filename = 'jokes.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered a total of 3851 topics\n"
     ]
    }
   ],
   "source": [
    "# gather topics\n",
    "page_topic_base_url = page_root_url + 'topics/'\n",
    "topics = set([])\n",
    "for i in ascii_lowercase :\n",
    "    page_topic_url = page_topic_base_url + i.upper()\n",
    "    page_response = requests.get(page_topic_url)\n",
    "    tree = html.fromstring(page_response.content)\n",
    "    all_topics_for_letter = tree.xpath('//div[@class=\"topicsList\"]//text()')\n",
    "    for topic_for_letter in all_topics_for_letter:\n",
    "        if len(topic_for_letter) > 1:\n",
    "            topics.add(topic_for_letter)\n",
    "            print(page_topic_url + ': ' + topic_for_letter)\n",
    "            clear_output(wait=True)\n",
    "topics = sorted(topics)\n",
    "topics = topics[1:]\n",
    "\n",
    "with open(topics_filename, 'wb') as fp:\n",
    "    pickle.dump(topics, fp)\n",
    "    \n",
    "print('Gathered a total of ' + str(len(topics)) + ' topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jokes(base_page_url, iter_, topic, jokes, first_joke, tot_n_jokes = 0):  \n",
    "    MAX_JOKE_LENGTH = 200\n",
    "    no_more_jokes = True\n",
    "    \n",
    "    final_page_url = base_page_url + str(iter_)\n",
    "    got_request = False\n",
    "    while not got_request:\n",
    "        try:\n",
    "            page_response = requests.get(final_page_url, stream=True)\n",
    "            got_request = True\n",
    "        except:\n",
    "            print('Taking a nap until the website responds zzzZZZ...')\n",
    "            sleep(5)\n",
    "    \n",
    "    tree = html.fromstring(page_response.content)    \n",
    "    joke_html_texts = tree.xpath('//p[@class=\"joke-inner\"]')\n",
    "    if len(joke_html_texts) == 0:\n",
    "        return no_more_jokes, jokes, tot_n_jokes\n",
    "    \n",
    "    for joke_html_text in joke_html_texts:\n",
    "        joke_text_list = [x for x in joke_html_text.itertext()]        \n",
    "        if len(joke_text_list) == 0:\n",
    "            return no_more_jokes, jokes, tot_n_jokes\n",
    "        formatted_joke = ' '.join(joke_text_list)\n",
    "        if formatted_joke == first_joke:\n",
    "            return no_more_jokes, jokes, tot_n_jokes        \n",
    "        if not formatted_joke.find('Read more') == 0 and len(formatted_joke) <= MAX_JOKE_LENGTH:\n",
    "            jokes[topic].append(formatted_joke)\n",
    "            print('Total number of jokes: ' + str(tot_n_jokes))\n",
    "            print('Topic ' + topic + ': ' + formatted_joke)\n",
    "            clear_output(wait=True)\n",
    "            tot_n_jokes += 1\n",
    "    \n",
    "    no_more_jokes = False\n",
    "    return no_more_jokes, jokes, tot_n_jokes\n",
    "\n",
    "def get_topic_jokes(topic,page_root_url,jokes, tot_n_jokes = 0):\n",
    "    final_page_url = page_root_url + topic + '/recent/'\n",
    "    jokes[topic] = []\n",
    "    first_joke = 'NotAJoke'\n",
    "    no_more_jokes, jokes, tot_n_jokes = get_jokes(final_page_url, 1, topic, jokes, first_joke, tot_n_jokes)\n",
    "    if no_more_jokes:\n",
    "        return jokes, no_more_jokes, tot_n_jokes\n",
    "    if len(jokes[topic]) > 0:\n",
    "        first_joke = jokes[topic][0]\n",
    "\n",
    "    for i in range(100):  \n",
    "        no_more_jokes, jokes, tot_n_jokes = get_jokes(final_page_url, i+2, topic, jokes, first_joke, tot_n_jokes)   \n",
    "        if no_more_jokes:            \n",
    "            break    \n",
    "    return jokes, no_more_jokes, tot_n_jokes       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last processed topic before interruption was: toy\n",
      "Total number of jokes: 42734\n",
      " Rohit: Easily, If One Is A Toyephant Go In A Fridge/\n"
     ]
    }
   ],
   "source": [
    "# if the joke scraping was interrupted, run this cell\n",
    "topics = pickle.load( open( topics_filename, \"rb\" ) ) \n",
    "\n",
    "jokes = {}\n",
    "tot_n_jokes = 0\n",
    "curr_topic = topics[0]\n",
    "try:\n",
    "    jokes = pickle.load( open(jokes_filename, \"rb\") )    \n",
    "    topics_without_jokes = []\n",
    "    for topic in topics:\n",
    "        n_jokes_topic = 0\n",
    "        if topic in jokes.keys():        \n",
    "            jokes_topic = jokes[topic]\n",
    "            for joke in jokes_topic:\n",
    "                n_jokes_topic+=1\n",
    "        else:\n",
    "            topics_without_jokes.append(topic)\n",
    "        tot_n_jokes += n_jokes_topic\n",
    "\n",
    "    jokes_topics = sorted(jokes.keys())\n",
    "    curr_topic = jokes_topics[-1]\n",
    "    print('Last processed topic before interruption was: ' + curr_topic)\n",
    "except:\n",
    "    print('Could not find file ' + jokes_filename + '. Starting from scratch.')\n",
    "    \n",
    "jokes[curr_topic] = []\n",
    "topics_to_process = topics[topics.index(curr_topic):]\n",
    "\n",
    "for topic in topics_to_process:\n",
    "    curr_topic = topic\n",
    "    jokes, no_more_jokes, tot_n_jokes = get_topic_jokes(topic,page_root_url,jokes,tot_n_jokes)\n",
    "    with open(jokes_filename, 'w+b') as fp:\n",
    "        pickle.dump(jokes, fp)\n",
    "    \n",
    "jokes = pickle.load( open(jokes_filename, \"rb\") )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = pickle.load( open( topics_filename, \"rb\" ) )   \n",
    "jokes = pickle.load( open( jokes_filename, \"rb\" ) )\n",
    "\n",
    "tot_n_jokes = 0\n",
    "topics_without_jokes = []\n",
    "for topic in topics:\n",
    "    if topic in jokes.keys():\n",
    "        n_jokes_topic = 0\n",
    "        jokes_topic = jokes[topic]\n",
    "        for joke in jokes_topic:\n",
    "            n_jokes_topic+=1\n",
    "    else:\n",
    "        topics_without_jokes.append(topic)\n",
    "    tot_n_jokes += n_jokes_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485\n"
     ]
    }
   ],
   "source": [
    "print(tot_n_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('curr_topic', 'wb') as fp:\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
